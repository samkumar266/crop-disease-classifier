# -*- coding: utf-8 -*-
"""Plant_Disease_Prediction_CNN_Image_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/samkumar266/crop-disease-classifier/blob/main/model_training_notebook/Plant_Disease_Prediction_CNN_Image_Classifier.ipynb

**Seeding for reproducibility**
"""

# Set seeds for reproducibility
import random
random.seed(0)

import numpy as np
np.random.seed(0)

import tensorflow as tf
tf.random.set_seed(0)

"""**Importing the dependencies**"""

import os
import json
from zipfile import ZipFile
from PIL import Image

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

"""**Data Curation**

Upload the kaggle.json file
"""

!pip install kaggle

kaggle_credentails = json.load(open("kaggle.json"))

from google.colab import drive
drive.mount('/content/drive')

# setup Kaggle API key as environment variables
os.environ['KAGGLE_USERNAME'] = kaggle_credentails["username"]
os.environ['KAGGLE_KEY'] = kaggle_credentails["key"]

!kaggle datasets download -d abdallahalidev/plantvillage-dataset

!ls

# Unzip the downloaded dataset
with ZipFile("plantvillage-dataset.zip", 'r') as zip_ref:
    zip_ref.extractall()

print(os.listdir("plantvillage dataset"))


print(len(os.listdir("plantvillage dataset/segmented")))
print(os.listdir("plantvillage dataset/segmented")[:5])

print(len(os.listdir("plantvillage dataset/color")))
print(os.listdir("plantvillage dataset/color")[:5])

print(len(os.listdir("plantvillage dataset/grayscale")))
print(os.listdir("plantvillage dataset/grayscale")[:5])

"""**Number of Classes = 38**"""

print(len(os.listdir("plantvillage dataset/color/Grape___healthy")))
print(os.listdir("plantvillage dataset/color/Grape___healthy")[:5])

"""**Data Preprocessing**"""

# Dataset Path
base_dir = 'plantvillage dataset/color'

image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'

# Read the image
img = mpimg.imread(image_path)

print(img.shape)
# Display the image
plt.imshow(img)
plt.axis('off')  # Turn off axis numbers
plt.show()

image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'

# Read the image
img = mpimg.imread(image_path)

print(img)

# Image Parameters
img_size = 224
batch_size = 32

#DATA AUGMENTATION & PREPROCESSING
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    fill_mode='nearest'
)

"""**Train Test Split**"""

# Image Data Generators
valid_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    validation_split=0.2
)

# Train Generator
print("\nLoading training data...")
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    subset='training',
    class_mode='categorical',
    shuffle=True
)

# Validation Generator
print("Loading validation data...")
validation_generator = valid_datagen.flow_from_directory(
    base_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    subset='validation',
    class_mode='categorical',
    shuffle=False
)

num_classes = train_generator.num_classes
print(f"\nNum classes: {num_classes}")
print(f"Training samples: {train_generator.samples}")
print(f"Validation samples: {validation_generator.samples}")

"""**Convolutional Neural Network**"""

# Model Definition
print("\nBuilding model...")
from tensorflow.keras.applications import MobileNetV2

base_model = MobileNetV2(
    input_shape=(img_size, img_size, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False   # freeze base

# Build top layers
inputs = layers.Input(shape=(img_size, img_size, 3))
x = base_model(inputs, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.4)(x)
x = layers.Dense(256, activation='relu')(x)
outputs = layers.Dense(num_classes, activation='softmax')(x)

model = models.Model(inputs, outputs)

# model summary
model.summary()

# Compile the Model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    verbose=1
)

"""**Model training**"""

# Training the Model
epochs = 12
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=epochs,
    callbacks=[early_stopping, reduce_lr]
)

"""**Model Evaluation**"""

# Model Evaluation
val_loss, val_acc = model.evaluate(validation_generator)
print(f"Validation accuracy: {val_acc*100:.2f}%  | val_loss: {val_loss:.4f}")

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.legend()
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend()
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Build true & predicted arrays across the validation generator
y_true = validation_generator.classes
# predict() on generator: ensure steps cover all samples
steps = int(np.ceil(validation_generator.samples / validation_generator.batch_size))
y_pred_probs = model.predict(validation_generator, steps=steps, verbose=1)
y_pred = np.argmax(y_pred_probs, axis=1)

# labels ordering
labels = list(train_generator.class_indices.keys())

# Confusion matrix
print("\nGenerating confusion matrix...")
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(16,16))
sns.heatmap(cm, cmap='Blues', annot=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Classification Report
print("\nClassification Report:")
print("="*70)
print(classification_report(y_true, y_pred, target_names=labels, digits=4))

print("\nSaving class indices...")
# Create class_indices mapping: {index: class_name}
class_indices = {v: k for k, v in train_generator.class_indices.items()}

# Save locally
with open('class_indices.json', 'w') as f:
    json.dump(class_indices, f, indent=2)
print("✓ Saved class_indices.json")

# SAVE model (.h5) locally and to Google Drive
print("\nSaving model...")
model_filename = "plant_disease_prediction_model.h5"
model.save(model_filename)
print(f"✓ Saved model locally: {model_filename}")

drive_out_dir = "/content/drive/MyDrive/trained_models"
os.makedirs(drive_out_dir, exist_ok=True)

drive_model_path = os.path.join(drive_out_dir, model_filename)
model.save(drive_model_path)
print(f"Saved model to Drive: {drive_model_path}")

# Save class_indices to Drive
drive_class_idx = os.path.join(drive_out_dir, "class_indices.json")
with open(drive_class_idx, 'w') as f:
    json.dump(class_indices, f, indent=2)
print(f"✓ Saved class_indices.json to Drive: {drive_class_idx}")

"""**Building a Predictive System**"""

print("\n" + "="*70)
print("SETTING UP PREDICTION FUNCTIONS")
print("="*70)


from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

def load_and_preprocess_image(image_path, target_size=(img_size, img_size)):
    """
    Load and preprocess a single image for prediction

    IMPORTANT: Uses MobileNetV2 preprocessing to match training!
    """
    # Load image
    img = Image.open(image_path).convert("RGB")
    # Resize
    img = img.resize(target_size)
    # Convert to array
    arr = np.array(img)
    # Apply MobileNetV2 preprocessing (scales to [-1, 1])
    arr = preprocess_input(arr)
    # Add batch dimension
    arr = np.expand_dims(arr, 0)
    return arr

def predict_image_class(model, image_path, class_indices):
    """
    Predict the class of a single image

    Args:
        model: Trained Keras model
        image_path: Path to image file
        class_indices: Dictionary mapping {index: class_name}

    Returns:
        predicted_class: Class name (string)
        confidence: Prediction confidence (float 0-1)
    """
    # Preprocess image
    x = load_and_preprocess_image(image_path)

    # Get predictions
    probs = model.predict(x, verbose=0)

    # Get predicted class index
    idx = int(np.argmax(probs, axis=1)[0])
    confidence = float(np.max(probs))

    # Map index to class name
    predicted_class = class_indices[idx]

    return predicted_class, confidence

def predict_top5(model, image_path, class_indices):
    """
    Get top 5 predictions with probabilities (useful for debugging)
    """
    x = load_and_preprocess_image(image_path)
    probs = model.predict(x, verbose=0)[0]

    # Get top 5 indices
    top5_idx = np.argsort(probs)[-5:][::-1]

    print(f"\nTop 5 Predictions:")
    print("="*60)
    for i, idx in enumerate(top5_idx, 1):
        print(f"{i}. {class_indices[idx]:40s} {probs[idx]*100:6.2f}%")
    print("="*60)

    return class_indices[top5_idx[0]], probs[top5_idx[0]]

def visualize_prediction(model, image_path, class_indices):
    """
    Visualize image with prediction
    """
    # Load and display original image
    img = Image.open(image_path).convert("RGB")

    # Get prediction
    pred, conf = predict_image_class(model, image_path, class_indices)

    # Plot
    plt.figure(figsize=(10, 6))
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Prediction: {pred}\nConfidence: {conf*100:.2f}%",
              fontsize=14, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.show()

    # Show top 5
    predict_top5(model, image_path, class_indices)

print("\n" + "="*70)
print("TESTING PREDICTIONS")
print("="*70)

# Single prediction
image_path = "/content/test_apple_black_rot.JPG"
pred, conf = predict_image_class(model, image_path, class_indices)
print(f"\nPrediction: {pred}")
print(f"Confidence: {conf*100:.2f}%")

# Visualize with top 5
visualize_prediction(model, image_path, class_indices)


# Upload and test your own image
print("\nTo test with your own image, run:")
print("""
from google.colab import files
uploaded = files.upload()

if uploaded:
    test_image_path = list(uploaded.keys())[0]
    visualize_prediction(model, test_image_path, class_indices)
""")

print("\n" + "="*70)
print("VERIFICATION CHECKS")
print("="*70)

# Verify preprocessing range
test_arr = np.random.rand(224, 224, 3) * 255
test_preprocessed = preprocess_input(test_arr.astype('float32'))
print(f"✓ Preprocessing range: [{test_preprocessed.min():.2f}, {test_preprocessed.max():.2f}]")
print("  (Should be approximately [-1, 1] for MobileNetV2)")

# Verify class indices
print(f"\n✓ Number of classes: {len(class_indices)}")
print(f"✓ Sample classes: {list(class_indices.values())[:3]}")

# Verify model
print(f"\n✓ Model input shape: {model.input_shape}")
print(f"✓ Model output shape: {model.output_shape}")

print("\n" + "="*70)
print("✓ TRAINING COMPLETED SUCCESSFULLY!")
print("="*70)
print(f"Final Validation Accuracy: {val_acc*100:.2f}%")
print("\nModels saved to:")
print(f"  - Local: {model_filename}")
print(f"  - Google Drive: {drive_model_path}")
print("="*70)



class_indices

"""**Save the model to Google drive or local**"""

